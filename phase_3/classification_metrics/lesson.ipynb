{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T21:03:49.549004Z", "start_time": "2021-04-08T21:03:49.545632Z"}}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n", "from sklearn.datasets import load_iris, make_classification\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.linear_model import LogisticRegression"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# On Classifier Evaluation"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Confusion Matrix\n", "\n", "For classification problems, the target is a categorical variable. This means that we can simply count the number of times that our model predicts the correct category and the number of times that it predicts something else.\n", "\n", "We can visualize this by means of a **confusion matrix**, which displays counts of correct and incorrect predictions. We'll explore this below. There are [many ways](https://docs.google.com/document/d/13Oi3lrJl-It0VOBw9EcjPHFkg3RqYp4nZ1Cx2uq-7VE/edit?usp=sharing) of evaluating a classification model, but most derive from the confusion matrix."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Lottery Number Prediction\n", "\n", "Suppose I want to train a model to predict whether a string of six numbers (a \"ticket\") would win the lottery or not. What sort of data might I use?\n", "\n", "### Scenario 1\n", "\n", "I gather all the winning tickets from the last 10000 days or so. So I have one column for the tickets themselves, and a Boolean column indicating whether the ticket was a winner or not.\n", "\n", "Now if all the tickets on which my model trains are *winning* tickets, then it would predict every ticket to win! Suppose I test the model on a set of 1000 tickets, and suppose that there is exactly one winning ticket among those 1000. My model will always predict the ticket to win. Let's think about what the confusion matrix will look like."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Setting up the true values\n", "y_true = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Setting up the predictions\n", "y_pred = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:56:34.322153Z", "start_time": "2021-04-08T20:56:34.317928Z"}}, "outputs": [], "source": ["# Defining the confusion matrix\n", "cm_1 = confusion_matrix(y_true, y_pred)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The confusion matrix should tell us that we have 999 false positives (999 losing tickets predicted to win) and 1 true positive (1 winning ticket predicted to win):"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:46:24.234082Z", "start_time": "2021-04-08T20:46:24.230672Z"}}, "outputs": [], "source": ["cm_1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Notice the way that sklearn displays its confusion matrix: The rows are \\['actually false', 'actually true'\\]; the columns are \\['predicted false', 'predicted true'\\].\n", "\n", "So it displays:\n", "\n", "$\\begin{bmatrix}\n", "TN & FP \\\\\n", "FN & TP\n", "\\end{bmatrix}$"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:46:25.059195Z", "start_time": "2021-04-08T20:46:25.056363Z"}}, "outputs": [], "source": ["tn = cm_1[0, 0]\n", "fp = cm_1[0, 1]\n", "fn = cm_1[1, 0]\n", "tp = cm_1[1, 1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's see if we can calculate some of our metrics for this matrix."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Accuracy** = $\\frac{TP + TN}{TP + TN + FP + FN}$\n", "\n", "In words: How often did my model get the right answer?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:58:49.953817Z", "start_time": "2021-04-08T20:58:49.951601Z"}}, "outputs": [], "source": ["# Accuracy\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Recall** = $\\frac{TP}{TP + FN}$\n", "\n", "In words: How often did my model correctly predict winning tickets?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:59:02.543563Z", "start_time": "2021-04-08T20:59:02.541297Z"}}, "outputs": [], "source": ["# Recall\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Precision** = $\\frac{TP}{TP + FP}$\n", "\n", "In words: How often was my model's prediction of 'winner' correct?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:59:14.753452Z", "start_time": "2021-04-08T20:59:14.751075Z"}}, "outputs": [], "source": ["# Precision\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**F-1 Score** = $\\frac{2PrRc}{Pr + Rc}$ = $\\frac{2TP}{2TP + FP + FN}$"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:59:33.929569Z", "start_time": "2021-04-08T20:59:33.927436Z"}}, "outputs": [], "source": ["# F-1 Score\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Scenario 2\n", "\n", "Well, my recall was good, but everything else I measured was terrible! Can I do better?\n", "\n", "This time I'll train my model in a much different way. I'll give it the tickets of 10000 people who played the lottery yesterday. Suppose that there are one winning ticket and 9999 losers. Now I test the model on the same 1000 tickets from before in Scenario 1.\n", "\n", "This time my model will almost always predict a ticket to lose. Suppose that, in the 1000 predictions, it makes only one prediction of a winner, and suppose that this prediction is wrong."]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T21:06:36.957625Z", "start_time": "2021-04-08T21:06:36.954764Z"}}, "outputs": [], "source": ["# Set up predictions\n", "y_pred_2 = None\n", "y_pred_2[0] = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Instead of coding out the scores by hand, we can use sklearn to speed things up."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import accuracy, precision, recall, and f1 from sklearn"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T21:08:21.098797Z", "start_time": "2021-04-08T21:08:21.088709Z"}}, "outputs": [], "source": ["# Print out the scores for each metric\n", "accuracy = accuracy_score(y_true, y_pred_2)\n", "precision = precision_score(y_true, y_pred_2)\n", "recall = recall_score(y_true, y_pred_2)\n", "f1 = f1_score(y_true, y_pred_2)\n", "\n", "print('Accuracy', accuracy)\n", "print('Precision', precision)\n", "print('Recall', recall)\n", "print('F1', f1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Resampling\n", "\n", "The last classifier had a really high accuracy, but everything else was terrible.\n", "\n", "In both cases, the problem we ran into was **class imbalance**. A popular solution for such a problem is resampling our data. To do this, let's take a look at [SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:46:31.561140Z", "start_time": "2021-04-08T20:46:31.141686Z"}}, "outputs": [], "source": ["from imblearn.over_sampling import SMOTE"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:46:31.659931Z", "start_time": "2021-04-08T20:46:31.635872Z"}}, "outputs": [], "source": ["data = make_classification(n_samples = 10000, weights=[0.1, 0.9])\n", "X = data[0]\n", "y = data[1]\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2021)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:46:32.057482Z", "start_time": "2021-04-08T20:46:32.041409Z"}}, "outputs": [], "source": ["# Check class balance for the training data\n", "pd.Series(y_train).value_counts(normalize=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This is a pretty imbalanced dataset. Only 10% of the data has a class of `0`.\n", "\n", "Let's use resampling to address this:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:46:32.841299Z", "start_time": "2021-04-08T20:46:32.812557Z"}}, "outputs": [], "source": ["resample = SMOTE(random_state=2021)\n", "X_train_resampled, y_train_resampled = resample.fit_resample(X_train, y_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:46:33.191466Z", "start_time": "2021-04-08T20:46:33.185722Z"}}, "outputs": [], "source": ["pd.Series(y_train_resampled).value_counts(normalize=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Multiple Classes\n", "\n", "We can understand these metrics of recall, precision, and the rest even if there are more than two classes in our classification problem."]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:46:45.914762Z", "start_time": "2021-04-08T20:46:45.909918Z"}}, "outputs": [], "source": ["flowers = load_iris()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:46:47.153420Z", "start_time": "2021-04-08T20:46:47.150104Z"}}, "outputs": [], "source": ["print(flowers.DESCR)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:46:55.002329Z", "start_time": "2021-04-08T20:46:54.998470Z"}}, "outputs": [], "source": ["dims_train, dims_test, spec_train, spec_test = train_test_split(flowers.data,\n", "                                                                flowers.target,\n", "                                                                test_size=0.5,\n", "                                                               random_state=2021)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:46:59.538976Z", "start_time": "2021-04-08T20:46:59.535048Z"}}, "outputs": [], "source": ["spec_train[:5]"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:47:07.328374Z", "start_time": "2021-04-08T20:47:07.323982Z"}}, "outputs": [], "source": ["ss_f = StandardScaler()\n", "\n", "ss_f.fit(dims_train)\n", "\n", "dims_train_sc = ss_f.transform(dims_train)\n", "dims_test_sc = ss_f.transform(dims_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:47:12.543744Z", "start_time": "2021-04-08T20:47:12.531010Z"}}, "outputs": [], "source": ["logreg_f = LogisticRegression(multi_class='multinomial',\n", "                             C=0.01, random_state=42)\n", "\n", "logreg_f.fit(dims_train_sc, spec_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:47:18.478116Z", "start_time": "2021-04-08T20:47:18.318759Z"}}, "outputs": [], "source": ["plot_confusion_matrix(estimator=logreg_f,\n", "                      X=dims_test_sc,\n", "                      y_true=spec_test,\n", "                     display_labels=[\n", "                         'setosa',\n", "                         'versicolor',\n", "                         'virginica'\n", "                            ]);"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:48:06.656182Z", "start_time": "2021-04-08T20:48:06.651992Z"}}, "outputs": [], "source": ["accuracy_score(spec_test,\n", "              logreg_f.predict(dims_test_sc))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:48:10.515621Z", "start_time": "2021-04-08T20:48:10.511509Z"}}, "outputs": [], "source": ["(29 + 15 + 22) / (spec_test.shape[0])"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:48:18.348681Z", "start_time": "2021-04-08T20:48:18.342834Z"}}, "outputs": [], "source": ["precision_score(spec_test,\n", "                logreg_f.predict(dims_test_sc),\n", "               average=None)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T21:29:26.590482Z", "start_time": "2021-04-08T21:29:26.588407Z"}}, "outputs": [], "source": ["# Calculate by hand\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T20:48:34.038017Z", "start_time": "2021-04-08T20:48:34.032186Z"}}, "outputs": [], "source": ["recall_score(spec_test,\n", "            logreg_f.predict(dims_test_sc),\n", "            average=None)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Calculate by hand\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For multi-class precision, the relevant denominator is a **column**; for multi-class recall, the relevant denominator is a **row**."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Which Metric Should I Care About?\n", "\n", "Well, it depends.\n", "\n", "### General Lessons\n", "\n", "First, let's make some general observations about the metrics we've so far defined.\n", "\n", "Accuracy:\n", "- Pro: Takes into account both false positives and false negatives.\n", "- Con: Can be misleadingly high when there is a significant class imbalance. (A lottery-ticket predictor that *always* predicts a loser will be highly accurate.)\n", "\n", "Recall:\n", "- Pro: Highly sensitive to false negatives.\n", "- Con: No sensitivity to false positives.\n", "\n", "Precision:\n", "- Pro: Highly sensitive to false positives.\n", "- Con: No sensitivity to false negatives.\n", "\n", "F-1 Score:\n", "- Harmonic mean of recall and precision.\n", "    - Pro: Balanced both recall and precision\n", "    - Con: Harder to interpret/explain"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Using classification metrics with sklearn's cross validation"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T21:18:32.245194Z", "start_time": "2021-04-08T21:18:32.238835Z"}}, "outputs": [], "source": ["# Import some classification data\n", "data = make_classification()\n", "X = data[0]\n", "y = data[1]\n", "\n", "# Create train test split\n", "from sklearn.model_selection import cross_val_score\n", "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=2021)\n", "\n", "# Create a model\n", "model = LogisticRegression(solver='lbfgs')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The metrics [found here](https://scikit-learn.org/stable/modules/model_evaluation.html) are built into sklearn's cross validation"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T21:18:33.507372Z", "start_time": "2021-04-08T21:18:33.401062Z"}}, "outputs": [], "source": ["recall = cross_val_score(model, X_train, y_train, scoring='recall', cv=5)\n", "precision = cross_val_score(model, X_train, y_train, scoring='precision', cv=5)\n", "f1 = cross_val_score(model, X_train, y_train, scoring='f1', cv=5)\n", "accuracy = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-04-08T21:18:34.278590Z", "start_time": "2021-04-08T21:18:34.273518Z"}}, "outputs": [], "source": ["print('Average recall:', recall.mean())\n", "print('Average precision:', precision.mean())\n", "print('Average f1:', f1.mean())\n", "print('Average accuracy:', accuracy.mean())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise\n", "\n", "If you wanted to use resampling with multiple fold cross validation, ***you cannot resample before making your cross validated splits***. When using resampling, you should always evaluate your model on *unbalanced* data. \n", "\n", "ie, the following would be *incorrect*\n", "```\n", "X_train, X_test, y_train, y_test = train_test_split(X,y)\n", "X_train, y_train = resample.fit_resample(X_train, y_train)\n", "\n", "scores = cross_val_score(model, X_train, y_train)\n", "```\n", "\n", "Because of this, you would need to write out the cross validation yourself using `Kfolds`.\n", "\n", "**In the cell below, comments have been provided to quide you through every step of this cross validation process.**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import KFold from sklearn\n", "\n", "# Import precision, recall, \n", "# accuracy, and precision from sklearn\n", "\n", "\n", "# Create a kfolds object\n", "\n", "# Create a list for each \n", "# classification score\n", "\n", "\n", "# Instantiate a logistic regression model\n", "\n", "# Instantiate a standard scaler\n", "\n", "# Instantiate a smote object\n", "\n", "\n", "# Loop over the training and validation indices\n", "# using the kfolds object\n", "\n", "    # Split X_train into a train and validation split\n", "\n", "    \n", "    # Scale and transform the training \n", "    # split using the standard scaler\n", "\n", "    \n", "    # Resample the training split\n", "    \n", "    # Fit the model to the resampled training split\n", "    \n", "    # Scale the validation split\n", "\n", "    # Produce predictions for the validation split\n", "\n", "    # Calculate the recall, precision, f1, and accuracy scores\n", "\n", "    # Append the calculated scores to their corresponding list\n", "\n", "    \n", "# Print the mean of each score list    "]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": false, "sideBar": true, "skip_h1_title": false, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 2}