{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 0
   },
   "source": [
    "# Topic 38: Time Series Models\n",
    "\n",
    "https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/\n",
    "\n",
    "* AR model (autoregression)\n",
    "* MA model (moving average)\n",
    "* ARMA model (autoregression + moving average)\n",
    "* Differencing model\n",
    "* ARIMA model (autoregression + differencing + moving average)\n",
    "* SARIMA model (seasonal ARIMA)\n",
    "* ARIMAX model (ARIMA + exogenous variables)\n",
    "* SARIMAX model (seasonal ARIMA + exogenous variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 1
   },
   "source": [
    "## Auto-regressive Time Series Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 2
   },
   "source": [
    "An autoregression model makes an assumption that the observations at previous time steps are useful to predict the value at the next time step. It is one of the simplest time series models in which we use a linear model to predict the value at the present time using the value at the previous time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 3
   },
   "source": [
    "<p style='text-align:center; font-size: 30px;'>ùëå<sub>t</sub>=ùúô<sub>1</sub>ùëå<sub>ùë°‚àí1</sub>+ùúñ<sub>ùë°</sub></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 4
   },
   "source": [
    "The numeral one (1) denotes that the next instance is solely dependent on the previous instance.  The ùúô(phi) is a coefficient which we seek so as to minimize the error function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 5
   },
   "source": [
    "The order of AR is the number of lag terms we are using to predict the present value (AR(1) uses only 1 lag - one value directly preceding the value you are trying to predict, AR(2) use the two values directly preceding the value you are trying to predict) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 6
   },
   "source": [
    "#### How do we determine the order aka how many lag terms do we include? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 7
   },
   "source": [
    "Using ACF and PACF! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 8
   },
   "source": [
    "\n",
    "<img src='../resources/AR(1).png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 9
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-notebook')\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 10
   },
   "source": [
    "# Load Data and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 11
   },
   "outputs": [],
   "source": [
    "#read in csv\n",
    "taxes = pd.read_csv('../resources/google-trends_taxes_us.csv', header=1).iloc[:-1]\n",
    "\n",
    "#set index to datetime and set frequency to Month Start ('MS')\n",
    "taxes['Month'] = pd.to_datetime(taxes['Month'], infer_datetime_format=True)\n",
    "taxes = taxes.set_index('Month')\n",
    "taxes.index.freq = 'MS'\n",
    "\n",
    "#plot of data to see visualize trends\n",
    "taxes.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 12
   },
   "source": [
    "Nope.  Do you remember what we did in the last class to make it stationary?\n",
    "\n",
    "We logged it to help remove the trend and changing covariance, took a 12 month difference to remove seasonality, and took another difference of 1 month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 13
   },
   "source": [
    "## Making Data Stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 14
   },
   "outputs": [],
   "source": [
    "adfuller(taxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 15
   },
   "outputs": [],
   "source": [
    "stationary_taxes = np.log(taxes).diff().diff()\n",
    "stationary_taxes = stationary_taxes.dropna()\n",
    "adfuller(stationary_taxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 16
   },
   "source": [
    "# Train-Test Split for Time Series\n",
    "\n",
    "When dividing your time series data for training and testing, we don't split it randomly like for some other kinds of modeling.  \n",
    "\n",
    "Why Not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": "Placeholder"
   },
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 18
   },
   "outputs": [],
   "source": [
    "# train-test-split for time series isn't random!\n",
    "split = int(len(taxes) * .9)\n",
    "full_train, holdout = stationary_taxes.iloc[:split], stationary_taxes.iloc[split:]\n",
    "\n",
    "second_split = int(len(full_train) * .9)\n",
    "train, test = full_train[:second_split], full_train[second_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 19
   },
   "source": [
    "### AR(1) Model\n",
    "\n",
    "What's going on below?  We have ARIMA(order=(1,0,0)).fit()\n",
    "\n",
    "First off, we are going to learn about MA, or moving average, models next.  The I denotes differencing that the model will perform (in case we didn't do it ourselves) to make the data stationary, and is called the Integrated component.\n",
    "\n",
    "AR(auto-regressive)\n",
    "\n",
    "I(Integrated)\n",
    "\n",
    "MA(moving average)\n",
    "\n",
    "ARIMA is a combination model, or an ARMA model with differencing.\n",
    "\n",
    "The 'order' argument tells the ARIMA model which lags to include in the model and many times to difference it.\n",
    "Order is often represented as (p,d,q)\n",
    "\n",
    "p = lags used in the AR part\n",
    "\n",
    "d = order of differencing to perform\n",
    "\n",
    "q = lags to use in the MA part.\n",
    "\n",
    "In the model below we will use (1,0,0) which is equivalent to just auto-regressive model only using 1 lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 20
   },
   "outputs": [],
   "source": [
    "# define a function to evaluate our models for us.\n",
    "def evaluate_model(model, data, train, test, train_predict_start=0):\n",
    "    \"\"\"\n",
    "    Takes a fitted ARIMA model, the original data, the train split and the test split.\n",
    "    optionally, can take a training starting point between 0 and len(train).  default = 0\n",
    "    optionally, can take forecast length to determine how far to forecast\n",
    "    shows a chart of data, train prediction, and test prediction\n",
    "    prints the MSE of the training prediction and the testing prediction\n",
    "    returns a summary object from model.summary()\n",
    "    \"\"\"\n",
    "    trainpreds = model.predict()\n",
    "    testpreds = model.forecast(len(test))\n",
    "\n",
    "    ax = plt.subplot(111)\n",
    "    trainpreds.name = 'training prediction'\n",
    "    testpreds.name = 'testing prediction'\n",
    "    trainpreds.plot(ax=ax)\n",
    "    testpreds.plot(ax=ax)\n",
    "    data.plot(ax=ax, color='Yellow')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    training_MSE = mean_squared_error(train, trainpreds)**.5\n",
    "    testing_MSE = mean_squared_error(test, testpreds)**.5\n",
    "    print('Training RMSE = ', training_MSE)\n",
    "    print('Testing RMSE = ', testing_MSE)\n",
    "    \n",
    "    return model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 21
   },
   "outputs": [],
   "source": [
    "# order = (p, d, q)\n",
    "# p - autoregressive\n",
    "# d - differences\n",
    "# q - moving average\n",
    "\n",
    "\n",
    "ar1 = ARIMA(train, order=(1,0,0)).fit()\n",
    "evaluate_model(ar1, stationary_taxes, train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 22
   },
   "source": [
    "#### Interpretation of AR(1) model\n",
    "\n",
    "How did our model do?  Let's interpret:\n",
    "\n",
    "The training preds are created by the `ar1.predict()` call.  This makes a prediction for each point in the data, based on the actual previous data.  So the prediction for time period k is used by regressing on the values for time points 0:k-1.\n",
    "\n",
    "The testing preds are created by `ar1.forecast()`.  Forecast predicts values for time periods after the stopping point of the training set passed.  It returns a number of predictions equal to the value passed, so `ar1.forecast(len(test))` will make a forecast a number of months ahead equal to the size of the testing slice of the data.\n",
    "\n",
    "What do you notice, visually comparing the actual data to the predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": "Placeholder"
   },
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 24
   },
   "source": [
    "If we look at the coefficients:\n",
    "const = intercept\n",
    "\n",
    "ar.L1 = coefficient for the first lag\n",
    "\n",
    "sigma2 = variance of the error term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 25
   },
   "source": [
    "### AR(2) Model\n",
    "\n",
    "What is the difference between an AR(2) and an AR(1) model?  Write your answer below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": "Placeholder"
   },
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 27
   },
   "outputs": [],
   "source": [
    "ar2 = ARIMA(train, order=(2,0,0)).fit()\n",
    "evaluate_model(ar2, stationary_taxes, train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 28
   },
   "source": [
    "#### Interpretation of AR(2) model\n",
    "\n",
    "Did we do better?  The training predictions were a little better, but we still don't realy have a great model yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 29
   },
   "source": [
    "## Moving Average Time Series Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 30
   },
   "source": [
    "Sometimes, a past value is not a useful indicator of what value will come next. Consider a system that is subject to a lot of shocks/volatility. If a previous time period experiences a shock it may cause an error for future predictions if we just that value. A moving average model helps address this behavior. \n",
    "\n",
    "A moving average term in a time series model is a past error (multiplied by a coefficient).\n",
    "\n",
    "An MA model assumes present value is related to errors in the past - includes memory of past errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 31
   },
   "source": [
    "<p style='text-align: center; font-size:30px;'>ùëå<sub>t</sub>=Œº + ùúñ<sub>ùë°</sub>+ùúÉ<sub>1</sub>ùúñ<sub>ùë°‚àí1</sub></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 32
   },
   "source": [
    "For more details on how this model is fit: https://stats.stackexchange.com/questions/26024/moving-average-model-error-terms/74826#74826 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 33
   },
   "source": [
    "## Differencing Model aka Integrated Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 34
   },
   "source": [
    "The differenced value is equal to the present value minus the value at the next lag. A time series which needs to be differenced to be made stationary is said to be an \"integrated\" time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 35
   },
   "source": [
    "<p>If d=0:  y<sub>t</sub>  =  Y<sub>t</sub></p>\n",
    "\n",
    "If d=1:  y<sub>t</sub> =  Y<sub>t</sub> - Y<sub>t-1</sub>\n",
    "\n",
    "If d=2:  y<sub>t</sub> =  (Y<sub>t</sub> - Y<sub>t-1</sub>) - (Y<sub>t-1</sub> - Y<sub>t-2</sub>)  =  Y<sub>t</sub> - 2Y<sub>t-1</sub> + Y<sub>t-2</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 36
   },
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 37
   },
   "source": [
    "Combines AR, Differencing (I), and MA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 38
   },
   "source": [
    "The differenced value is equal to the present value minus the value at the next lag. A time series which needs to be differenced to be made stationary is said to be an \"integrated\" time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 39
   },
   "source": [
    "<p style ='text-align:center; font-size: 30px;'>ùëå<sub>t</sub>=ùúô<sub>1</sub>ùëå<sub>ùë°‚àí1</sub>+ùúô<sub>2</sub>ùëå<sub>ùë°‚àí2</sub>...ùúô<sub>ùëù</sub>ùëå<sub>t‚àíùëù</sub>+ùúñ<sub>ùë°</sub>+ùúÉ<sub>1</sub>ùúñ<sub>ùë°‚àí1</sub>+ùúÉ<sub>2</sub>ùúñ<sub>ùë°‚àí2</sub>+...ùúÉ<sub>ùëû</sub>ùúñ<sub>ùë°‚àíùëû</sub></p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 40
   },
   "source": [
    "ARIMA has three main parameters we need to input, p, d, & q\n",
    "\n",
    "<b>p:</b> The number of AR terms we are going to include<br/>\n",
    "<b>d:</b> The number of times we are differencing our data<br/>\n",
    "<b>q:</b> The number MA terms we are going to include"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 41
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 42
   },
   "source": [
    "The ACF help us to find the right logs to use with the MA component of our model, or our `q` component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 43,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ACF/PACF to determine which terms in include (MA or AR or Both?)\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "#take the log of the original taxes data, since we both logged and differenced to make our data stationary before.  \n",
    "# ARIMA does not log the data for us.\n",
    "log_taxes = np.log(taxes)\n",
    "\n",
    "#remember we set 'split' to be .9 * len(taxes)\n",
    "log_full_train, log_holdout = log_taxes[:split], log_taxes[split:]\n",
    "\n",
    "# log_train, log_test = log_full_train[:second_split], log_full_train[second_split:]\n",
    "log_train, log_test = log_full_train[:second_split], log_full_train[second_split:]\n",
    "\n",
    "#plot autocorrelation for each lag (alpha is confidence interval).  We used the differenced data because we are looking \n",
    "# because we will difference it in the ARIMA model.  \n",
    "plot_acf(log_train.diff().diff().dropna(), alpha=.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 44
   },
   "source": [
    "We use the PACF to determine logs for the AR part of the model, the `p` component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 45
   },
   "outputs": [],
   "source": [
    "plot_pacf(log_train.diff().diff().dropna(), alpha=.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 46
   },
   "source": [
    "**Note**\n",
    "The ARIMA model reverses the differencing in the predictions, so the predictions from an ARIMA model with `d=2` will return predictions on the same scale as the original data.  This is one of the benefits of this model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 47,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "arima1 = ARIMA(log_train, order=(2,2,1)).fit()\n",
    "\n",
    "evaluate_model(arima1, log_taxes, log_train, log_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 48
   },
   "source": [
    "Examining the p-values for the lags tells us that many of the lags we included are not statistically relevant.  We can give an ARIMA model a tuple of lags, rather than just a integer.  An integer includes all lags up to the integer value.  A tuple only includes those lags in the tuple.  \n",
    "\n",
    "Examining the coefficients above, which lags should we try including in our model next time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": "Placeholder"
   },
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 50
   },
   "source": [
    "Even better, we could use a SARIMAX model to account for the seasonality in the data, rather than trying to figure out the right lags to fit on for them.  There is some information about SARIMAX models at the bottom of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 51
   },
   "source": [
    "### Tuning P, D, and Q\n",
    "\n",
    "In practice, we often need to tune p,d, and q using strategies similar to hyperparameter tuning in other models.  Often we try many different values and see which ones work best.  However ACF and PACF graphs help us make informed guesses rather than random ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 52
   },
   "source": [
    "## ARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 53
   },
   "source": [
    "ARIMA with eXogenous variables - extend ARIMA to include additional variables that might have an impact on what we are are trying to forecast. \n",
    "\n",
    "Considerations: \n",
    "\n",
    "1) Does our exogenous variable actually impact our endogenous variable (and not the other way around - use granger causality test) \n",
    "\n",
    "2) Exogenous variables need to be differenced at the same order as the endogenous "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 54
   },
   "source": [
    "### Endogenous Variables\n",
    "\n",
    "So far we've only been using Endogenous variables.  Those are the variables that we trying to forecast, in this case the valume of searches for taxes on Google Search in the USA.\n",
    "\n",
    "### Exogenous Variables\n",
    "\n",
    "Exogenous Variables are extra variables outside of the data we are trying to predict.  These might be holidays or weekends, they might be search volumes for other terms, or anything else that can be aligned with the datetime period and are not endogenous.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 55
   },
   "source": [
    "<img src='../resources/seasonal_data.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 56
   },
   "source": [
    "### SARIMAX\n",
    "\n",
    "SARIMAX integrates the ARIMA model we've been using, as well as dealing more gracefully with (S)easonal trends and  e(X)ogenous variables.\n",
    "\n",
    "You can read more about SARIMAX models below\n",
    "\n",
    "\n",
    "https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 57
   },
   "source": [
    "1. Plot data, see if there are trends <br/>\n",
    "2. If trends, remove them (differencing, log transform, etc) <br/>\n",
    "3. If seasonal trends are there determine periodicity. <br/>\n",
    "4. ACF and PACF of  data <br/>\n",
    "5. Determine order of differencing, AR, or MA (or both) <br/>\n",
    "6. Build model and evaluate \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seasonal_order - (p,d,q,s)\n",
    "\n",
    "s = periodicity of the seasonality, or how many periods between each season.\n",
    "\n",
    "In our case, it's 12 periods, or 1 year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "res = seasonal_decompose(log_full_train)\n",
    "plot_acf(res.seasonal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(res.seasonal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 58
   },
   "source": [
    "Try the below SARIMAX model on your own.  What might be some exogenous variables you coudl use for this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 59
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "sarimax = SARIMAX(log_train, exog=None, order=(1, 2, 2), seasonal_order=(4, 2, 2, 12)).fit()\n",
    "evaluate_model(sarimax, log_taxes, log_train, log_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "sarimax2 = SARIMAX(log_full_train, exog=None, order=(1, 2, 2), seasonal_order=(4, 2, 2, 12)).fit()\n",
    "evaluate_model(sarimax2, log_taxes, log_full_train, log_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 60
   },
   "source": [
    "# Additional Resources\n",
    "\n",
    "* Modeling cheat sheet: https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/\n",
    "* AutoARIMA: https://towardsdatascience.com/time-series-forecasting-using-auto-arima-in-python-bb83e49210cd\n",
    "* SARIMAX Project walkthrough: https://towardsdatascience.com/newyork-taxi-demand-forecasting-with-sarimax-using-weather-data-d46c041f3f9c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "195.27px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
